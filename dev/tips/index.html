<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tips · RiskAdjustedLinearizations.jl</title><link rel="canonical" href="https://juliadocs.github.io/Documenter.jl/stable/tips/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">RiskAdjustedLinearizations.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../risk_adjusted_linearization/">Risk-Adjusted Linearizations</a></li><li><a class="tocitem" href="../numerical_algorithms/">Numerical Algorithms</a></li><li><a class="tocitem" href="../example/">Example</a></li><li><a class="tocitem" href="../caching/">Caching</a></li><li><a class="tocitem" href="../diagnostics/">Diagnostics</a></li><li class="is-active"><a class="tocitem" href>Tips</a><ul class="internal"><li><a class="tocitem" href="#ccgf-tips-1"><span>Deriving the conditional cumulant generating function</span></a></li><li><a class="tocitem" href="#Writing-functions-compatible-with-automatic-differentiation-1"><span>Writing functions compatible with automatic differentiation</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tips</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/chenwilliam77/RiskAdjustedLinearizations.jl/blob/master/docs/src/tips.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="tips-1"><a class="docs-heading-anchor" href="#tips-1">Tips</a><a class="docs-heading-anchor-permalink" href="#tips-1" title="Permalink"></a></h1><p>This page of the documentation holds miscellaneous tips for using the package.</p><h2 id="ccgf-tips-1"><a class="docs-heading-anchor" href="#ccgf-tips-1">Deriving the conditional cumulant generating function</a><a class="docs-heading-anchor-permalink" href="#ccgf-tips-1" title="Permalink"></a></h2><p>The cumulant generating function is based upon the moment-generating function. If</p><div>\[\begin{aligned}
M_X(t) \equiv \mathbb{E}[e^{tX}],\quad \quad \quad t\in \mathbb{R},
\end{aligned}\]</div><p>is the moment-generating function of a random variable <span>$X$</span>, then the cumulant-generating function is just</p><div>\[\begin{aligned}
cgf_X(t) \equiv \log\mathbb{E}[e^{tX}],\quad \quad \quad t\in \mathbb{R}.
\end{aligned}\]</div><p>As an example, if <span>$X \sim N(\mu, \sigma^2)$</span>, then <span>$M_X(t) = \exp(t\mu + \sigma^2 t^2 / 2)$</span> and <span>$cgf_X(t) = t\mu + \sigma^2 t^2 / 2$</span>.</p><p>Risk-adjusted linearizations imply that the relative entropy measure <span>$\mathcal{V}(\Gamma_5 z_{t + 1} + \Gamma_6 y_{t + 1})$</span> becomes a vector of conditional cumulant-generating functions for the random variables <span>$A_i(z_t) \varepsilon_{t + 1}`, where$</span>A<em>i(z</em>t)<span>$is the$</span>i``th row vector of</p><div>\[\begin{aligned}
A(z_t) = (\Gamma_5 + \Gamma_6 \Psi)(I_{n_z} - \Lambda(z_t) \Psi)^{-1} \Sigma(z_t).
\end{aligned}\]</div><p>To create a <code>RiskAdjustedLinearization</code>, the user needs to define a function <code>ccgf</code> in the form <code>ccgf(F, A, z)</code> or <code>ccgf(A, z)</code>, where <code>A</code> refers to the matrix <span>$A(z_t)$</span> once it has already been evaluated at <span>$z_t$</span>. In other words, the input <code>A</code> should seen as a <code>n_y \times n_\varepsilon</code> matrix of real scalars. However, depending on the distributions of the martingale difference sequence <span>$\varepsilon_{t + 1}$</span>, writing the conditional cumulant-generating function may also require knowing the current state <span>$z_t$</span>.</p><p>Let us consider two didactic examples. First, assume <span>$\varepsilon_{t + 1}\sim \mathcal{N}(0, I)$</span>. Then we claim</p><pre><code class="language-none">ccgf(A, z) = sum(A.^2, dims = 2) / 2</code></pre><p>Based on the definition of <span>$\mathcal{V}(z_t)$</span>, one may be tempted to derive the conditional cumulant-generating function for the random vector <code>A(z_t) \varepsilon_{t + 1}</code>. However, this is not actually what we want. Rather, <code>ccgf</code> should just return a vector of conditional cumulant-generating functions for the <span>$n_y$</span> random variables <span>$X_i = A_i(z_t)\varepsilon_{t + 1}$</span>.</p><p>Because the individual components of <span>$\varepsilon_{t + 1}$</span> are independent, the moment-generating function for <span>$X_i$</span> is <span>$\exp\left(\frac{1}{2}\left(\sum_{j = 1}^{n_\varepsilon} X_{ij} \varepsilon_{i, t + j}\right)\right)$</span>, hence the <span>$i$</span>th cumulant-generating function is <span>$\frac{1}{2}\left(\sum_{j = 1}^{n_\varepsilon} X_{ij} \varepsilon_{i, t + j}$</span>. This is precisely what the code above achieves.</p><p>Second, let us consider a more complicated example. In the <a href="../example/#example-1">Wachter (2013) Example</a>, the ccgf is</p><pre><code class="language-none">function ccgf(F, α, z) # α is used here instead of A
    # the S term in z[S[:p]] is just an ordered dictionary mapping the symbol :p to the desired index of z
    F .= .5 .* α[:, 1].^2 + .5 * α[:, 2].^2 + (exp.(α[:, 3] + α[:, 3].^2 .* δ^2 ./ 2.) .- 1. - α[:, 3]) * z[S[:p]]
end</code></pre><p>Observe that the first two quantities <code>.5 .* α[:, 1].^2 + .5 * α[:, 2].^2</code> resemble what would be obtained from a standard multivariate normal distribution. The remaining terms are more complicated because the Wachter (2013) model involves a Poisson mixture of normal distributions. It will be instructive to spell the details out.</p><p>Consumption growth follows the exogenous process</p><div>\[\begin{aligned}
c_{t + 1} = \mu + c_t + \sigma \varepsilon^c_{t + 1} - \theta \xi_{t + 1},
\end{aligned}\]</div><p>where <span>$\varepsilon_t^c \sim N(0, 1)$</span> is iid over time and <span>$\xi_t \mid j_t \sim N(j_t, j_t\delta^2)$</span>, where the number of jumps <span>$j_t \sim Poisson(p_{t - 1})$</span>, hence <span>$\mathbb{E}_t \xi_{t + 1} = \mathbb{E}_t j_{t + 1} = p_t$</span>. Assume that <span>$\varepsilon_t^c$</span> and <span>$\varepsilon_t^\xi = \xi_t - \mathbb{E}_{t - 1}\xi_t$</span> are independent. Finally, the intensity <span>$p_t$</span> follows the process</p><div>\[\begin{aligned}
p_{t + 1} = (1 - \rho_p) p + \rho_p p_t + \sqrt{p_t} \phi_p \sigma \varepsilon_{t + 1}^p,
\end{aligned}\]</div><p>where <span>$\varepsilon_t^p \sim N(0, 1)$</span> is iid over time and independent of <span>$\varepsilon_t^c$</span> and <span>$\varepsilon_t^\xi$</span>.</p><p>Note that <span>$\xi_t$</span> and <span>$\mathbb{E}_{t - 1}\xi_t$</span> are not independent because <span>$\mathbb{E}_{t - 1}\xi_t = p_{t - 1}$</span> and <span>$j_t \sim Poisson(p_{t - 1})$</span>, hence a higher <span>$p_{t - 1}$</span> implies <span>$\xi_t$</span> is more likely to be higher. Re-centering <span>$\xi_t$</span> by <span>$\mathbb{E}_{t - 1}\xi_t$</span> creates a martingale difference sequence since <span>$\xi_t \mid j_t$</span> is normal.</p><p>By independence of the components of <span>$\varepsilon_t = [\varepsilon_t^c, \varepsilon_t^p, \varepsilon_t^\xi]^T$</span>, the conditional cumulant-generating function for the <span>$i$</span>th row of the <span>$A(z_t)$</span> matrix described in this <a href="../risk_adjusted_linearization/#affine-theory-1">section</a> is</p><div>\[\begin{aligned}
\kappa_i[A_i(z_t) \mid z_t] &amp;  =  \log\mathbb{E}_t[\exp(A_{i1}(z_t) \varepsilon_{t + 1}^c)]  + \log\mathbb{E}_t[\exp(A_{i2}(z_t) \varepsilon_{t + 1}^p)] + \log\mathbb{E}_t[\exp(A_{i3}(z_t) \varepsilon_{t + 1}^\xi)].
\end{aligned}\]</div><p>The first two terms on the RHS are for normal random variables and simplify to <span>$(A_{i1}(z_t)^2 + A_{i2}(z_t)^2) / 2$</span>. To calculate the remaining term, note that <span>$\mathbb{E}_{t}\xi_{t + 1} = p_t$</span> is already part of the information set at <span>$z_t$</span>, hence</p><div>\[\begin{aligned}
\log\mathbb{E}_t[\exp(A_{i3}(z_t) \varepsilon_{t + 1}^\xi)] = \log\left[\frac{1}{\exp(A_{i3}(z_t) p_t)}\mathbb{E}_t\left[\exp(A_{i3}(z_t) \xi_t)\right]\right] = \log\mathbb{E}_t\left[\exp(A_{i3}(z_t) \xi_t)\right] - A_{i3}(z_t) p_t.
\end{aligned}\]</div><p>To calculate the cumulant-generating function of <span>$\xi_t$</span>, we use the results for mixture distributions in <a href="https://www.jstor.org/stable/27643733?seq=2#metadata_info_tab_contents">Villa and Escobr (2006)</a> or <a href="https://www.atlantis-press.com/journals/jsta/125944282/view">Bagui et al. (2020)</a>. Given random variables <span>$X$</span> and <span>$Y$</span>, assume the conditional distribution <span>$X\mid Y$</span> and the marginal distribution for <span>$Y$</span> are available. If we can write the moment-generating function for the random variable <span>$X\mid Y$</span> as</p><div>\[\begin{aligned}
M_{X \mid Y}(s) = C_1(s) \exp(C_2(s) Y),
\end{aligned}\]</div><p>then the moment-generating function of <span>$X$</span> is</p><div>\[\begin{aligned}
M_{X}(s) = C_1(s) M_Y[C_2(s)].
\end{aligned}\]</div><p>In our case, we have</p><div>\[\begin{aligned}
M_{\xi_t \mid j_t}(s) = \exp\left(s j_t  + \frac{1}{2} s^2 \delta^2j_t  \right),
\end{aligned}\]</div><p>hence <span>$C_1(s) = 0$</span> and <span>$C_2(s) = (s + s^2\delta^2 / 2)$</span>. The variable <span>$j_t$</span> has a Poisson distribution with intensity <span>$p_t$</span>, which implies the moment-generating function</p><div>\[\begin{aligned}
M_{j_t}(s) = \exp((\exp(s) - 1) p_t).
\end{aligned}\]</div><p>Thus, as desired,</p><div>\[\begin{aligned}
\log\mathbb{E}_t\left[\exp(A_{i3}(z_t) \xi_t)\right] - A_{i3}(z_t) p_t &amp; = (\exp(A_{i3}(z_t)  + A_{i3}(z_t)^2\delta^2) - 1)p_t - A_{i3}(z_t) p_t.
\end{aligned}\]</div><p>Computing this quantity for each expectational equation yields the <code>ccgf</code> used in the <a href="../example/#example-1">Wachter (2013) Example</a>.</p><h2 id="Writing-functions-compatible-with-automatic-differentiation-1"><a class="docs-heading-anchor" href="#Writing-functions-compatible-with-automatic-differentiation-1">Writing functions compatible with automatic differentiation</a><a class="docs-heading-anchor-permalink" href="#Writing-functions-compatible-with-automatic-differentiation-1" title="Permalink"></a></h2><ul><li><p><strong>Use an in-place function to avoid type errors.</strong></p><p>For example, define the <code>ccgf</code> as <code>ccgf(F, x)</code>. You can use the element type of <code>F</code> via <code>eltype(F)</code> to ensure that you don&#39;t get a type error from using <code>Float64</code> instead of <code>Dual</code> inside the function. If <code>ccgf</code> was out-of-place, then depending on how the vector being returned is coded, you may get a type error if elements of the return vector are zero or constant numbers. By having <code>F</code> available, you can guarantee these numbers can be converted to <code>Dual</code> types if needed without always declaring them as <code>Dual</code> types.</p></li></ul><ul><li><p><strong>Use <code>dualvector</code> or <code>dualarray</code>.</strong></p><p>The package provides these two helper functions in the case where you have a function <code>f(x, y)</code>, and you need to be able to automatcally differentiate with respect to <code>x</code> and <code>y</code> separately. For example, the nonlinear terms of the expectational equation <code>ξ(z, y)</code> takes this form. Within , you can pre-allocate the return vector by calling <code>F = RiskAdjustedLinearizations.dualvector(z, y)</code>. The <code>dualvector</code> function will infer from <code>z</code> and <code>y</code> whether <code>F</code> should be have <code>Dual</code> element types or not so you can repeatedly avoid writing if-else conditional blocks. The <code>dualarray</code> function generalizes this to arbitrary <code>AbstractMatrix</code> inputs. See the out-of-place function for <code>ξ</code> in <a href="https://github.com/chenwilliam77/RiskAdjustedLinearizations/tree/master/examples/wachter_disaster_risk/wachter.jl">examples/wachter_disaster_risk/wachter.jl</a>.</p></li></ul><ul><li><p><strong>Don&#39;t pre-allocate the return vector.</strong></p><p>Instead of pre-allocating the return vector at the  top of the function for an out-of-place function, just concatenate the individual elements  at the very end. Julia will figure out the appropriate element type for you. The downside of this  approach is that you won&#39;t be able to assign names to the specific indices of the return vector (e.g.  does this equation define the risk-free interest rate?). For small models, this disadvantage is generally not a problem.  See the definition of the out-of-place expected state transition function <code>μ</code> in <a href="https://github.com/chenwilliam77/RiskAdjustedLinearizations/tree/master/examples/wachter_disaster_risk/wachter.jl">examples/wachter_disaster_risk/wachter.jl</a>.</p></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../diagnostics/">« Diagnostics</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 12 November 2020 16:33">Thursday 12 November 2020</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
